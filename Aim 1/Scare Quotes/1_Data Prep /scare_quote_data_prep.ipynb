{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTKA00zH04KwX8BX0HioLk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/Diss_Detecting_Provider_Bias/blob/main/Aim%201/Scare%20Quotes/1_Data%20Prep%20/scare_quote_data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e_jJIxYma-D",
        "outputId": "4df409ed-6267-406f-b6fb-fbcc3226af7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import scipy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BigQuery"
      ],
      "metadata": {
        "id": "GYGMRwJgnh7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 'project_id' with your BigQuery project ID\n",
        "\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project='detecting-bias-mimic-iii')\n",
        "\n",
        "icd_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_clinical.diagnoses_icd\n",
        "                LIMIT 1000''')\n",
        "\n",
        "icd = client.query(icd_query).to_dataframe()\n",
        "\n"
      ],
      "metadata": {
        "id": "76ci9q6dnjel"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICD codes"
      ],
      "metadata": {
        "id": "ZxEZ_dROm-Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Filter for ICD codes for 282.60-282.69, referring to sickle cell types w/wo crisis\n",
        "#2824 for thalassemia w + w/o crisis (282.41-282.42)\n",
        "#SCD: 2826,2824\n",
        "#Chronic Pain 3382\n",
        "#Opioid dependencies: 3040,3047 (combo),\n",
        "#HIV/AIDS ^042$\n",
        "\n",
        "icds_of_interest = icd[icd['ICD9_CODE'].str.contains('2826|2824|3040|3047|3382|^042$', na=False)]\n",
        "# Issues here-- will cause more leading numbers\n",
        "print(icds_of_interest.head())\n",
        "\n",
        "icds_of_interest.info()\n",
        "\n",
        "#patients_unique = icds_of_interest['SUBJECT_ID'].drop_duplicates()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qenQlyfVm5Fu",
        "outputId": "f254ae13-b6c5-4ef3-a0c9-991c9ef608be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
            "784   176454       15872   139593        3     73382\n",
            "889   196755       17664   123887        7     33829\n",
            "1090  594591       87552   117940       10     30471\n",
            "1119  596984       88064   107776       13     33829\n",
            "1666  642343       98048   151449        3       042\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1945 entries, 784 to 651018\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   ROW_ID      1945 non-null   Int64 \n",
            " 1   SUBJECT_ID  1945 non-null   Int64 \n",
            " 2   HADM_ID     1945 non-null   Int64 \n",
            " 3   SEQ_NUM     1945 non-null   Int64 \n",
            " 4   ICD9_CODE   1945 non-null   object\n",
            "dtypes: Int64(4), object(1)\n",
            "memory usage: 98.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes and patients load"
      ],
      "metadata": {
        "id": "eFo4Bhh4m_fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "note_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_notes.noteevents''')\n",
        "\n",
        "NOTES = client.query(note_query).to_dataframe()\n",
        "\n",
        "peek_notes = NOTES.head()\n",
        "print(peek_notes)\n",
        "\n",
        "## Patients\n",
        "\n",
        "patient_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_clinical.patients''')\n",
        "\n",
        "PATIENTS = client.query(patient_query).to_dataframe()\n",
        "\n",
        "peek_patients = PATIENTS.head()\n",
        "print(peek_patients)\n",
        "\n",
        "biased_notes_corpus = NOTES.merge(PATIENTS, on = 'SUBJECT_ID')\n",
        "\n",
        "\n",
        "biased_notes_patients_corpus = biased_notes_corpus.merge(PATIENTS, on = 'SUBJECT_ID')\n",
        "\n",
        "biased_notes_patients_corpus.info()\n",
        "# Find unique chart types and decide to limit them\n",
        "    # Remove Radiology, ECG, Respiratory, Echo notes\n",
        "biased_notes_patients_corpus_filtered = biased_notes_patients_corpus[biased_notes_patients_corpus[\"CATEGORY\"].str.contains(\"Radiology|ECG|Respiratory|Echo\")==False]\n",
        "# biased_notes_patients_corpus_filtered.to_csv(\"biased_notes_patients_corpus_filtered.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCtUfH54m7FZ",
        "outputId": "38b85353-7c2c-4346-f59b-1f0e0b831add"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ROW_ID  SUBJECT_ID  HADM_ID   CHARTDATE           CHARTTIME  \\\n",
            "0   651001       74253   138344  2195-01-02 2195-01-02 01:11:00   \n",
            "1   447646       93610   112025  2181-02-28 2181-02-28 18:16:00   \n",
            "2   665160       70516   199605  2189-03-18 2189-03-18 16:24:00   \n",
            "3  1410461       11276   108792  2117-06-09 2117-06-09 06:14:00   \n",
            "4  1565250       23189   177182  2109-01-31 2109-01-31 13:25:00   \n",
            "\n",
            "            STORETIME       CATEGORY            DESCRIPTION   CGID  ISERROR  \\\n",
            "0 2195-01-02 05:18:01        Nursing  Nursing Progress Note  20345     <NA>   \n",
            "1 2181-02-28 18:58:52        Nursing  Nursing Progress Note  15527     <NA>   \n",
            "2 2189-03-18 18:15:36        Nursing  Nursing Progress Note  14768     <NA>   \n",
            "3 2117-06-09 06:24:00  Nursing/other                 Report  21570     <NA>   \n",
            "4 2109-01-31 13:32:00  Nursing/other                 Report  20818     <NA>   \n",
            "\n",
            "                                                TEXT  \n",
            "0  Respiratory failure, acute (not ARDS/[**Doctor...  \n",
            "1  Pt presented to ED from [**Hospital1 189**] wi...  \n",
            "2  Pain control (acute pain, chronic pain)\\n   As...  \n",
            "3  Neuro: Pt alert and oriented most of the noc. ...  \n",
            "4  CCU Progress Note:\\n\\nPt seen by cardiology te...  \n",
            "   ROW_ID  SUBJECT_ID GENDER        DOB        DOD   DOD_HOSP    DOD_SSN  \\\n",
            "0      49          56      F 1804-01-02 2104-01-08 2104-01-08 2104-01-08   \n",
            "1   17808       18848      F 2042-08-21 2128-01-08 2128-01-08 2128-01-08   \n",
            "2   36390       61056      F 2067-04-11 2152-01-08 2152-01-08 2152-01-08   \n",
            "3   25371       26889      F 2115-11-04 2164-01-08 2164-01-08 2164-01-08   \n",
            "4   17328       18333      F 2094-01-21 2168-01-08 2168-01-08 2168-01-08   \n",
            "\n",
            "   EXPIRE_FLAG  \n",
            "0            1  \n",
            "1            1  \n",
            "2            1  \n",
            "3            1  \n",
            "4            1  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2083180 entries, 0 to 2083179\n",
            "Data columns (total 25 columns):\n",
            " #   Column         Dtype         \n",
            "---  ------         -----         \n",
            " 0   ROW_ID_x       Int64         \n",
            " 1   SUBJECT_ID     Int64         \n",
            " 2   HADM_ID        Int64         \n",
            " 3   CHARTDATE      dbdate        \n",
            " 4   CHARTTIME      datetime64[ns]\n",
            " 5   STORETIME      datetime64[ns]\n",
            " 6   CATEGORY       object        \n",
            " 7   DESCRIPTION    object        \n",
            " 8   CGID           Int64         \n",
            " 9   ISERROR        Int64         \n",
            " 10  TEXT           object        \n",
            " 11  ROW_ID_y       Int64         \n",
            " 12  GENDER_x       object        \n",
            " 13  DOB_x          datetime64[ns]\n",
            " 14  DOD_x          datetime64[ns]\n",
            " 15  DOD_HOSP_x     datetime64[ns]\n",
            " 16  DOD_SSN_x      datetime64[ns]\n",
            " 17  EXPIRE_FLAG_x  Int64         \n",
            " 18  ROW_ID         Int64         \n",
            " 19  GENDER_y       object        \n",
            " 20  DOB_y          datetime64[ns]\n",
            " 21  DOD_y          datetime64[ns]\n",
            " 22  DOD_HOSP_y     datetime64[ns]\n",
            " 23  DOD_SSN_y      datetime64[ns]\n",
            " 24  EXPIRE_FLAG_y  Int64         \n",
            "dtypes: Int64(9), datetime64[ns](10), dbdate(1), object(5)\n",
            "memory usage: 431.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode by sentence, regex quote match"
      ],
      "metadata": {
        "id": "xv66agb8nLkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "full_dataframe = biased_notes_patients_corpus_filtered\n",
        "# Tokenize by sentence\n",
        "nlp = English()  # just the language with no model\n",
        "\n",
        "nlp.add_pipe('sentencizer')\n",
        "full_dataframe[\"Sentence\"] = full_dataframe[\"TEXT\"].apply(lambda x: [sent.text for sent in nlp(x).sents])\n",
        "full_dataframe = full_dataframe.explode(\"Sentence\", ignore_index=True)\n",
        "full_dataframe.rename(columns={\"Unnamed: 0\": \"ROW_ID_new\"}, inplace=True)\n",
        "full_dataframe.index.name = \"Sentence ID\"\n",
        "\n",
        "full_dataframe['Sentence'].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True)\n",
        "\n",
        "regex = \"\\\"(.+?)\\\"\"\n",
        "quoted_dataframe = full_dataframe.loc[full_dataframe['Sentence'].str.contains(regex)]\n",
        "\n",
        "quoted_dataframe[\"scare_quote\"] = \"\"\n",
        "quoted_dataframe[\"annotator_comments\"] = \"\"\n",
        "quoted_dataframe[\"not_patient_quote\"] = \"\"\n",
        "# 3842 quoted charts sentences total of 1,510,650 sentences\n",
        "quoted_dataframe2 = quoted_dataframe.drop_duplicates(subset=['Sentence'])\n",
        "quoted_dataframe2.to_csv(\"quoted_dataframe_annotate.csv\")\n",
        "\n",
        "len(np.unique(quoted_dataframe2['CGID']))\n",
        "# 545 caregivers\n",
        "len(np.unique(quoted_dataframe2['ROW_ID_x']))\n",
        "len(np.unique(quoted_dataframe2['SUBJECT_ID']))\n",
        "len(np.unique(quoted_dataframe2['HADM_ID']))\n",
        "\n"
      ],
      "metadata": {
        "id": "LTRd7oW_nJwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore the Data\n"
      ],
      "metadata": {
        "id": "vrdxgmAxmzhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "data.quoted_dataframe2()"
      ],
      "metadata": {
        "id": "LS7WrGInuZYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}