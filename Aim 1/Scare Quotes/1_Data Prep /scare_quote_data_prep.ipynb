{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaofAKKbeON9kxEZRJx1n6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/Diss_Detecting_Provider_Bias/blob/main/scare_quote_data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e_jJIxYma-D",
        "outputId": "4df409ed-6267-406f-b6fb-fbcc3226af7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import scipy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BigQuery"
      ],
      "metadata": {
        "id": "GYGMRwJgnh7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace 'project_id' with your BigQuery project ID\n",
        "\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project='detecting-bias-mimic-iii')\n",
        "\n",
        "icd_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_clinical.diagnoses_icd\n",
        "                LIMIT 1000''')\n",
        "\n",
        "icd = client.query(icd_query).to_dataframe()\n",
        "\n"
      ],
      "metadata": {
        "id": "76ci9q6dnjel"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICD codes"
      ],
      "metadata": {
        "id": "ZxEZ_dROm-Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Filter for ICD codes for 282.60-282.69, referring to sickle cell types w/wo crisis\n",
        "#2824 for thalassemia w + w/o crisis (282.41-282.42)\n",
        "#SCD: 2826,2824\n",
        "#Chronic Pain 3382\n",
        "#Opioid dependencies: 3040,3047 (combo),\n",
        "#HIV/AIDS ^042$\n",
        "\n",
        "icds_of_interest = icd[icd['ICD9_CODE'].str.contains('2826|2824|3040|3047|3382|^042$', na=False)]\n",
        "# Issues here-- will cause more leading numbers\n",
        "print(icds_of_interest.head())\n",
        "\n",
        "icds_of_interest.info()\n",
        "\n",
        "#patients_unique = icds_of_interest['SUBJECT_ID'].drop_duplicates()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qenQlyfVm5Fu",
        "outputId": "f254ae13-b6c5-4ef3-a0c9-991c9ef608be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
            "784   176454       15872   139593        3     73382\n",
            "889   196755       17664   123887        7     33829\n",
            "1090  594591       87552   117940       10     30471\n",
            "1119  596984       88064   107776       13     33829\n",
            "1666  642343       98048   151449        3       042\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1945 entries, 784 to 651018\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   ROW_ID      1945 non-null   Int64 \n",
            " 1   SUBJECT_ID  1945 non-null   Int64 \n",
            " 2   HADM_ID     1945 non-null   Int64 \n",
            " 3   SEQ_NUM     1945 non-null   Int64 \n",
            " 4   ICD9_CODE   1945 non-null   object\n",
            "dtypes: Int64(4), object(1)\n",
            "memory usage: 98.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes and patients load"
      ],
      "metadata": {
        "id": "eFo4Bhh4m_fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "note_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_notes.noteevents''')\n",
        "\n",
        "NOTES = client.query(note_query).to_dataframe()\n",
        "\n",
        "peek_notes = NOTES.head()\n",
        "print(peek_notes)\n",
        "\n",
        "## Patients\n",
        "\n",
        "patient_query = ('''SELECT *\n",
        "                FROM physionet-data.mimiciii_clinical.patients''')\n",
        "\n",
        "PATIENTS = client.query(patient_query).to_dataframe()\n",
        "\n",
        "peek_patients = PATIENTS.head()\n",
        "print(peek_patients)\n",
        "\n",
        "biased_notes_corpus = NOTES.merge(PATIENTS, on = 'SUBJECT_ID')\n",
        "\n",
        "\n",
        "biased_notes_patients_corpus = biased_notes_corpus.merge(PATIENTS, on = 'SUBJECT_ID')\n",
        "\n",
        "biased_notes_patients_corpus.info()\n",
        "# Find unique chart types and decide to limit them\n",
        "    # Remove Radiology, ECG, Respiratory, Echo notes\n",
        "biased_notes_patients_corpus_filtered = biased_notes_patients_corpus[biased_notes_patients_corpus[\"CATEGORY\"].str.contains(\"Radiology|ECG|Respiratory|Echo\")==False]\n",
        "# biased_notes_patients_corpus_filtered.to_csv(\"biased_notes_patients_corpus_filtered.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LCtUfH54m7FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode by sentence, regex quote match"
      ],
      "metadata": {
        "id": "xv66agb8nLkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "full_dataframe = biased_notes_patients_corpus_filtered\n",
        "# Tokenize by sentence\n",
        "nlp = English()  # just the language with no model\n",
        "\n",
        "nlp.add_pipe('sentencizer')\n",
        "full_dataframe[\"Sentence\"] = full_dataframe[\"TEXT\"].apply(lambda x: [sent.text for sent in nlp(x).sents])\n",
        "full_dataframe = full_dataframe.explode(\"Sentence\", ignore_index=True)\n",
        "full_dataframe.rename(columns={\"Unnamed: 0\": \"ROW_ID_new\"}, inplace=True)\n",
        "full_dataframe.index.name = \"Sentence ID\"\n",
        "\n",
        "full_dataframe['Sentence'].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True)\n",
        "\n",
        "regex = \"\\\"(.+?)\\\"\"\n",
        "quoted_dataframe = full_dataframe.loc[full_dataframe['Sentence'].str.contains(regex)]\n",
        "\n",
        "quoted_dataframe[\"scare_quote\"] = \"\"\n",
        "quoted_dataframe[\"annotator_comments\"] = \"\"\n",
        "quoted_dataframe[\"not_patient_quote\"] = \"\"\n",
        "# 3842 quoted charts sentences total of 1,510,650 sentences\n",
        "quoted_dataframe2 = quoted_dataframe.drop_duplicates(subset=['Sentence'])\n",
        "quoted_dataframe2.to_csv(\"quoted_dataframe_annotate.csv\")\n",
        "\n",
        "len(np.unique(quoted_dataframe2['CGID']))\n",
        "# 545 caregivers\n",
        "len(np.unique(quoted_dataframe2['ROW_ID_x']))\n",
        "len(np.unique(quoted_dataframe2['SUBJECT_ID']))\n",
        "len(np.unique(quoted_dataframe2['HADM_ID']))\n",
        "\n"
      ],
      "metadata": {
        "id": "LTRd7oW_nJwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vrdxgmAxmzhr"
      }
    }
  ]
}
