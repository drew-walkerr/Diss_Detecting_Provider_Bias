{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "history_visible": true,
      "authorship_tag": "ABX9TyM+oChlhs+Mtn/6U+hJ0enH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/Diss_Detecting_Provider_Bias/blob/main/stigmatizing_labels_lexicon_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Levenshtein in terminal"
      ],
      "metadata": {
        "id": "_pW53BgIPPJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Q7YZh8JhsK",
        "outputId": "f4a9f30e-4142-4fe7-e207-4064ea5e9104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "_bv8_Wp_MmMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02293606-0cba-4fcb-a748-737ae5404412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import Cython\n",
        "import openai\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from collections import defaultdict\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import Levenshtein, re\n",
        "import sys\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "kSAvW6PDKxze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/Stigmatizing Labels/1_Data Prep\n",
        "%ls"
      ],
      "metadata": {
        "id": "hihS408RC0xC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0289463-e95f-4b1a-a3f0-f920a97ed055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/Stigmatizing Labels/1_Data Prep\n",
            "1_stigmatizing_labels_word_embeddings.py\n",
            "stigma_expanded_misspellings.csv\n",
            "stigmatizing_labels_dataframe_annotate.csv\n",
            "stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\n",
            "stigmatizing_labels_lexicon_dev.ipynb\n",
            "stigmatizing_labels_regex.ipynb\n",
            "stigmatizing_word_list_round_1_dw_pruned.csv\n",
            "stigma_word_list_round_2.csv\n",
            "trig-vectors-phrase.bin\n",
            "trig-vectors-phrase.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading word2vec model"
      ],
      "metadata": {
        "id": "L0VCU7pt8NWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're using BioWordVec, trained on MIMIC-III data:\n",
        "\n",
        "1. Zhang Y, Chen Q, Yang Z, Lin H, Lu Z. BioWordVec, improving biomedical word embeddings with subword information and MeSH. Scientific Data. 2019.\n",
        "2. Chen Q, Peng Y, Lu Z. BioSentVec: creating sentence embeddings for biomedical texts. The 7th IEEE International Conference on Healthcare Informatics. 2019."
      ],
      "metadata": {
        "id": "ZPRmbiUzLjWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abeed's 3B Twitter Drug Use Word Embeddings\n",
        "#model = KeyedVectors.load_word2vec_format('trig-vectors-phrase.bin', binary=True, encoding='latin-1')\n",
        "\n",
        "# BioWordVec, trained on MIMIC-III\n",
        "model = KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/BioWordVec_PubMed_MIMICIII_d200.vec.bin', binary = True)\n",
        "#model_path = \"/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/BioWordVec_PubMed_MIMICIII_d200.bin\"\n",
        "#model = KeyedVectors.load(model_path)\n",
        "#model = Word2Vec.load(model_path)\n",
        "\n",
        "\n",
        "#model2 = gensim.models.Word2Vec.load('trig-vectors-phrase.bin')\n",
        "\n",
        "#model2 = KeyedVectors.load_word2vec_format('trig-vectors-phrase.txt', binary=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_zXyxskB8KrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stigmatizing Labels and Negative Patient Descriptors\n",
        "* NIDA Words Matter list\n",
        "* Extra words selected by substance use experts previously used for MOUD stigma/bias (Jenn Drew and Abeed)\n",
        "* Negative patient descriptor list"
      ],
      "metadata": {
        "id": "x8in2sZC8SUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# stigma OR bias OR stereotype OR abuser OR stereotype\n",
        "# NIDA: https://www.drugabuse.gov/nidamed-medical-health-professionals/health-professions-education/words-matter-terms-to-use-avoid-when-talking-about-addiction\n",
        "# Words Matter: Words to avoid when talking about addiction:\n",
        "# Included: Addict, User, Abuser, Junkie, Alcoholic, Drunk, Habit, Dirty,\n",
        "# Added in this study: stigma, bias, stereotype, shame, blame (From studies on stigma, bias, and types of stigmatization referenced in literature)\n",
        "# Not included: clean, addicted baby, opioid substitution replacement therapy, medication-assisted treatment, former addict, reformed adict\n",
        "\n",
        "# Negative Patient Descriptors: Documenting Racial Bias in the Electronic Health Record, Sun et al. 2022\n",
        "# \"non-adherent\", \"aggressive\", \"agitated\", \"angry\", \"challenging\", \"combative\", \"non-compliant\", \"confront\", \"non-cooperative\", \"defensive\", \"exaggerate\", \"hysterical\", \"un-pleasant\", \"refuse\", \"resist\"\n",
        "# \"Frequent flyer\": https://jamanetwork.com/journals/jama/article-abstract/2551660?casa_token=Ruhau9aozs4AAAAA:Z39Z-m3vkuSi2rR-pmk7d_IkActub3A062BvSMGsUt9gfPs6rUGNC2lv727Z7ngimGYjpuOLlw\n",
        "# \"reluctant\" add? 1. Zestcott CA, Spece L, McDermott D, Stone J. Health Care Providers’ Negative Implicit Attitudes and Stereotypes of American Indians. J Racial and Ethnic Health Disparities. 2021;8(1):230-236. doi:10.1007/s40615-020-00776-w\n",
        "\n",
        "\n",
        "bias_stem_words = [\"abuser\",\"junkie\",\"alcoholic\", \"drunk\", \"drug-seeking\",\"nonadherent\", \"agitated\", \"angry\", \"combative\", \"noncompliant\", \"confront\", \"noncooperative\", \"defensive\", \"hysterical\", \"unpleasant\", \"refuse\",\"frequent-flyer\", \"reluctant\"]\n",
        "\n",
        "# Pruning while checking first round of results (regex search)-- 6/27/2023\n",
        "# Abuser-- 26k-- often describe as disorder-- ethanol abuse, alcohol abuse, may just be product of times-- poor labels. May want to reduce \"abuse\" for matching\n",
        "# resist removed, came up a lot as restitance /resistant related to tissue/infection\n",
        "# Addict-- always catches addiction, (referring to addiction team) see if we can add word break\n",
        "# Aggressive removed, similar issue -- 31k matches\n",
        "# Agititated -- 40k , is this more of a symptom?\n",
        "# Exaggerate -- 500, mostly describes condition\n",
        "# Alcoholic-- 6000, often describes alcoholic pancreatitis\n",
        "# Blame-- added by Drew during MOUD study, 127-- often describes patient idea of illness. Goal is not patient describing being blamed or blaming things\n",
        "# Confront-- catching confrontation, i.e. \"visual fields are full d/t confrontation\"\n",
        "# habit-- remove. Body/bowel habitus . 3602 caught. Though sometimes referred to \"toxic habits\"?\n",
        "# Challenging-- usually refers to the complexity of the medical situation, consider removing\n",
        "# removed dirty -- usually refers to wound or something\n",
        "# Removed shame, stereotype, bias -- these were more useful in the MOUD study\n",
        "\n",
        "bias_words_df = pd.DataFrame({\n",
        "    'stem_word': bias_stem_words\n",
        "})"
      ],
      "metadata": {
        "id": "0ZoYHIJf8Q0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bias_words_df['most_similar_words'] = bias_words_df['stem_word'].apply(model.most_similar)\n",
        "\n",
        "bias_words_df_2 = bias_words_df.explode(\"most_similar_words\", ignore_index=True)\n",
        "bias_words_df_2['new_word_id'] = range(1, 1 + len(bias_words_df_2))\n",
        "# bias_words_df_2[['similar_word','similarity_score']] =\n",
        "words_sep = pd.DataFrame(bias_words_df_2['most_similar_words'].values.tolist())\n",
        "words_sep['new_word_id'] = range(1, 1 + len(bias_words_df_2))\n",
        "bias_words_3 = bias_words_df_2.merge(words_sep, on = 'new_word_id')\n",
        "#bias_words_3['similar_word'], bias_words_3['score'] = bias_words_3[3],bias_words_3[4]\n",
        "\n",
        "bias_words_3= bias_words_3.rename(columns={0: \"similar_word\", 1: \"score\"})\n",
        "bias_words_3[\"Relevant_to_study\"] = \"\"\n",
        "bias_words_3.to_csv(\"stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\")\n",
        "\n",
        "bias_words_3"
      ],
      "metadata": {
        "id": "6QKm74hL-TG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "c3ecb39f-332a-49be-8bec-e95d2eeeb646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     stem_word                   most_similar_words  new_word_id  \\\n",
              "0       abuser      (ivdabuser, 0.8800737261772156)            1   \n",
              "1       abuser       (abuser's, 0.8708785176277161)            2   \n",
              "2       abuser  (abused-abuser, 0.8705908060073853)            3   \n",
              "3       abuser        (abusers, 0.8689486980438232)            4   \n",
              "4       abuser   (abuse/abuser, 0.8643447756767273)            5   \n",
              "..         ...                                  ...          ...   \n",
              "175  reluctant    (unreluctant, 0.8748424053192139)          176   \n",
              "176  reluctant   (arereluctant, 0.8744778633117676)          177   \n",
              "177  reluctant      (unwilling, 0.8688457608222961)          178   \n",
              "178  reluctant    (unwillingly, 0.8600345849990845)          179   \n",
              "179  reluctant      (-reluctant, 0.846684455871582)          180   \n",
              "\n",
              "      similar_word     score Relevant_to_study  \n",
              "0        ivdabuser  0.880074                    \n",
              "1         abuser's  0.870879                    \n",
              "2    abused-abuser  0.870591                    \n",
              "3          abusers  0.868949                    \n",
              "4     abuse/abuser  0.864345                    \n",
              "..             ...       ...               ...  \n",
              "175    unreluctant  0.874842                    \n",
              "176   arereluctant  0.874478                    \n",
              "177      unwilling  0.868846                    \n",
              "178    unwillingly  0.860035                    \n",
              "179     -reluctant  0.846684                    \n",
              "\n",
              "[180 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b2078d9-55ee-4751-8e60-1ad07e0eabec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stem_word</th>\n",
              "      <th>most_similar_words</th>\n",
              "      <th>new_word_id</th>\n",
              "      <th>similar_word</th>\n",
              "      <th>score</th>\n",
              "      <th>Relevant_to_study</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abuser</td>\n",
              "      <td>(ivdabuser, 0.8800737261772156)</td>\n",
              "      <td>1</td>\n",
              "      <td>ivdabuser</td>\n",
              "      <td>0.880074</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abuser</td>\n",
              "      <td>(abuser's, 0.8708785176277161)</td>\n",
              "      <td>2</td>\n",
              "      <td>abuser's</td>\n",
              "      <td>0.870879</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abuser</td>\n",
              "      <td>(abused-abuser, 0.8705908060073853)</td>\n",
              "      <td>3</td>\n",
              "      <td>abused-abuser</td>\n",
              "      <td>0.870591</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abuser</td>\n",
              "      <td>(abusers, 0.8689486980438232)</td>\n",
              "      <td>4</td>\n",
              "      <td>abusers</td>\n",
              "      <td>0.868949</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abuser</td>\n",
              "      <td>(abuse/abuser, 0.8643447756767273)</td>\n",
              "      <td>5</td>\n",
              "      <td>abuse/abuser</td>\n",
              "      <td>0.864345</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>reluctant</td>\n",
              "      <td>(unreluctant, 0.8748424053192139)</td>\n",
              "      <td>176</td>\n",
              "      <td>unreluctant</td>\n",
              "      <td>0.874842</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>reluctant</td>\n",
              "      <td>(arereluctant, 0.8744778633117676)</td>\n",
              "      <td>177</td>\n",
              "      <td>arereluctant</td>\n",
              "      <td>0.874478</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>reluctant</td>\n",
              "      <td>(unwilling, 0.8688457608222961)</td>\n",
              "      <td>178</td>\n",
              "      <td>unwilling</td>\n",
              "      <td>0.868846</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>reluctant</td>\n",
              "      <td>(unwillingly, 0.8600345849990845)</td>\n",
              "      <td>179</td>\n",
              "      <td>unwillingly</td>\n",
              "      <td>0.860035</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>reluctant</td>\n",
              "      <td>(-reluctant, 0.846684455871582)</td>\n",
              "      <td>180</td>\n",
              "      <td>-reluctant</td>\n",
              "      <td>0.846684</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b2078d9-55ee-4751-8e60-1ad07e0eabec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b2078d9-55ee-4751-8e60-1ad07e0eabec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b2078d9-55ee-4751-8e60-1ad07e0eabec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following 10 most similar words identified, we'll use  stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv to filter out words deemed irrelevant to study by JL and DW."
      ],
      "metadata": {
        "id": "sIrhzlVq-Y1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Lexicon-Word Prune\n",
        "\n",
        "* Following word embeddings expansion, we manually pruned list to remove any words which may not relate to stigmatizing patient labels or words which may prove to be especially noisy in medical text.\n",
        "\n",
        "* Next, another step of pruning was conducted to assess matched words within MIMIC-III. We assessed the first 10-20 matches with each word in the stigmatizing labels lexicon and removed several which referred exclusively to medical procedures or were otherwise extremely common in EHR. (i.e. exaggerates, suspected).\n",
        "\n",
        "Below, we read back in the pruned word list, where appropriate words are given a \"1\" value in the column \"Relevant_to_study\".\n",
        "\n"
      ],
      "metadata": {
        "id": "4RATkUDy-Nx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Read in CSV of manually pruned list of first round expansion of Doubt lexicon\n",
        "bias_stem_words_round_2_raw = pd.read_csv(\"stigmatizing_word_list_round_1_dw_pruned.csv\")\n",
        "# filter for 0s\n",
        "bias_stem_words_round_2 = bias_stem_words_round_2_raw[bias_stem_words_round_2_raw[\"Relevant_to_study\"]==1]\n",
        "\n",
        "bias_stem_words_round_2.to_csv(\"stigma_word_list_round_2.csv\")\n",
        "\n",
        "bias_stem_words_round_2[\"similar_word\"] = bias_stem_words_round_2[\"similar_word\"].replace(\"_\", \" \", regex = True)\n",
        "\n",
        "bias_expanded_word_list = bias_stem_words_round_2[\"similar_word\"]"
      ],
      "metadata": {
        "id": "fediWTrj-Mro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220eedcc-0b68-4d58-9a4a-8980cd1b8787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-63ca85832b15>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  bias_stem_words_round_2[\"similar_word\"] = bias_stem_words_round_2[\"similar_word\"].replace(\"_\", \" \", regex = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github Code"
      ],
      "metadata": {
        "id": "uicKnEZFeAid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git config --global user.email \"andrew.walker@emory.edu\"\n",
        "#!git config --global user.name \"drew-walkerr\"\n",
        "#!git add \"stigmatizing_labels_lexicon_dev.ipynb\" \"stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\"\n"
      ],
      "metadata": {
        "id": "BUnt32YSeC2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!git commit -m \"created working BioWordVec expanded words for stigmatizing labels lexicon\"\n",
        "#!git push origin master # https://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@github.com/drew-walkerr/Diss_Detecting_Provider_Bias.git"
      ],
      "metadata": {
        "id": "R6ooORlVeIwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat GPT to expand search\n",
        "\n",
        "Finally, we utilized Chat GPT to generate 50 additional words, in an attempt to identify other terms that may be used by providers which impart stigmatizing labels to patients.\n",
        "\n",
        "We used the text-davinci-002, with the prompt:\n",
        "```\n",
        "prompt = \"Imagine that you are an expert in studying the linguistic transmission of provider bias towards stigmatized patient groups within electronic health records. I will present you with a list of stigmatizing words. Generate a new list of 25 additional words, separated by commas, which may be used which may stigmatize patients, typically written in medical charts. These words could be stigmatizing labels based on race, gender, or condition. Your response should be in JSON format. Here is the original list:\\n\\n\" + \"\\n\\n\".join(stigma_word_list)\n",
        "```\n",
        "**bold text**\n",
        "Prompt engineering best practices"
      ],
      "metadata": {
        "id": "avohCVLfuEII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stigma_word_list_round_2 = pd.read_csv(\"stigma_word_list_round_2.csv\")\n",
        "\n",
        "openai.api_key = pd.read_csv(\"/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/openai_api.csv\", header=None).iloc[0, 0]\n",
        "\n",
        "stigma_word_list = list(stigma_word_list_round_2[\"similar_word\"])\n"
      ],
      "metadata": {
        "id": "tZtuF24ohqW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional call to Chat GPT\n",
        "\n",
        "https://platform.openai.com/docs/guides/gpt/function-calling\n",
        "\n"
      ],
      "metadata": {
        "id": "D8Po6DaHQf-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "\n",
        "def generate_terms(new_stigmatizing_labels):\n",
        "    \"\"\"Generate a new list of 50 additional words,  which may be used which may stigmatize patients, typically written in medical charts. These words could be stigmatizing labels based on race, gender, or condition.\"\"\"\n",
        "    stigmatizing_labels = {\n",
        "        \"new_stigmatizing_labels\": ','.join(stigma_word_list),\n",
        "    }\n",
        "    return json.dumps(stigmatizing_labels)\n",
        "\n",
        "\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "messages = [{\"role\": \"system\", \"content\": \"Imagine that you are an expert in studying the linguistic transmission of provider bias towards stigmatized patient groups within electronic health records. Here a previously-developed list of stigmatizing patient descriptors and labels:\\n\\n\" + \"\\n\\n\".join(stigma_word_list)},\n",
        "        {\"role\": \"user\", \"content\": \"Generate a new list of 50 additional words,  which may be used which may stigmatize patients, typically written in medical charts. These words could be stigmatizing labels based on race, gender, or condition.\"}]\n",
        "functions = [\n",
        "        {\n",
        "            \"name\": \"generate_terms\",\n",
        "            \"description\": \"Generate a new list of 50 additional words,  which may be used which may stigmatize patients, typically written in medical charts. These words could be stigmatizing labels based on race, gender, or condition.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"new_stigmatizing_labels\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"A new list of 50 additional words which may be used by providers to stigmatize patients in electronic health records\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"new_stigmatizing_labels\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0613\",\n",
        "      messages=messages,\n",
        "      functions=functions,\n",
        "      function_call=\"auto\",  # auto is default, but we'll be explicit\n",
        "    )\n",
        "response_message = response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"]\n",
        "\n",
        "response_message\n",
        "response_message_clean = response_message[30:-2]\n",
        "\n",
        "stigma_gpt_list = response_message_clean.split(\",\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L9V9Lq6LQdYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine chat gpt-generated word list with existing list, checking for duplicates. None found."
      ],
      "metadata": {
        "id": "Aj03DQLzv0-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Compare the lists of strings \"stigma_gpt_list\" and stigma_word_list. Return all their duplicates, as well as a dataframe of their combined words with duplicates removed.\n",
        "\n",
        "# ID duplicates in the two lists\n",
        "list(set(stigma_gpt_list).intersection(set(stigma_word_list)))\n",
        "\n",
        "print (stigma_gpt_list)\n",
        "# Create a dataframe of the two lists with duplicates removed\n",
        "chat_gpt_df = pd.DataFrame(stigma_gpt_list)\n",
        "chat_gpt_df[\"similar_word\"] = chat_gpt_df[0]\n",
        "chat_gpt_df[\"stem_word\"] = \"chat_gpt\"\n",
        "chat_gpt_df.drop(columns = [0])\n",
        "\n",
        "# Bind rows of chat_gpt_df and bias_stem_word_round_2, inputting NA for unmatched columns in chat_gpt_df\n",
        "bias_stem_words_round_2.append(chat_gpt_df).to_csv(\"stigma_word_list_round_3_gpt.csv\")\n"
      ],
      "metadata": {
        "id": "Xj-9u6I4m5gb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}