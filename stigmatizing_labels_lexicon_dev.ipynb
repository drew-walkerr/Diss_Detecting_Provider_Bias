{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNMldHv2I1gSnQKcBFyUjlI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/Diss_Detecting_Provider_Bias/blob/main/stigmatizing_labels_lexicon_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Levenshtein in terminal"
      ],
      "metadata": {
        "id": "_pW53BgIPPJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Q7YZh8JhsK",
        "outputId": "59c5e40e-079b-42a7-80dc-d9ada1e56386"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "_bv8_Wp_MmMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3a7ac7-a408-4323-8ca1-95b4b0223186"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import Cython\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from collections import defaultdict\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import Levenshtein, re\n",
        "import sys\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "kSAvW6PDKxze"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/Stigmatizing Labels/1_Data Prep\n",
        "%ls"
      ],
      "metadata": {
        "id": "hihS408RC0xC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86503f20-af1e-4c97-dd47-dc3bb2cd68fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/Stigmatizing Labels/1_Data Prep\n",
            "1_stigmatizing_labels_word_embeddings.py\n",
            "doubt_word_list_round_2.csv\n",
            "stigma_expanded_misspellings.csv\n",
            "stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\n",
            "stigmatizing_labels_lexicon_dev.ipynb\n",
            "stigmatizing_labels_regex.ipynb\n",
            "stigmatizing_word_list_round_1_dw_pruned.csv\n",
            "trig-vectors-phrase.bin\n",
            "trig-vectors-phrase.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading word2vec model"
      ],
      "metadata": {
        "id": "L0VCU7pt8NWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're using BioWordVec, trained on MIMIC-III data:\n",
        "\n",
        "1. Zhang Y, Chen Q, Yang Z, Lin H, Lu Z. BioWordVec, improving biomedical word embeddings with subword information and MeSH. Scientific Data. 2019.\n",
        "2. Chen Q, Peng Y, Lu Z. BioSentVec: creating sentence embeddings for biomedical texts. The 7th IEEE International Conference on Healthcare Informatics. 2019."
      ],
      "metadata": {
        "id": "ZPRmbiUzLjWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abeed's 3B Twitter Drug Use Word Embeddings\n",
        "#model = KeyedVectors.load_word2vec_format('trig-vectors-phrase.bin', binary=True, encoding='latin-1')\n",
        "\n",
        "# BioWordVec, trained on MIMIC-III\n",
        "model = KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/BioWordVec_PubMed_MIMICIII_d200.vec.bin', binary = True)\n",
        "#model_path = \"/content/gdrive/MyDrive/Diss_Detecting_Provider_Bias/Aim 1/BioWordVec_PubMed_MIMICIII_d200.bin\"\n",
        "#model = KeyedVectors.load(model_path)\n",
        "#model = Word2Vec.load(model_path)\n",
        "\n",
        "\n",
        "#model2 = gensim.models.Word2Vec.load('trig-vectors-phrase.bin')\n",
        "\n",
        "#model2 = KeyedVectors.load_word2vec_format('trig-vectors-phrase.txt', binary=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_zXyxskB8KrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stigmatizing Labels and Negative Patient Descriptors\n",
        "* NIDA Words Matter list\n",
        "* Extra words selected by substance use experts previously used for MOUD stigma/bias (Jenn Drew and Abeed)\n",
        "* Negative patient descriptor list"
      ],
      "metadata": {
        "id": "x8in2sZC8SUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# stigma OR bias OR stereotype OR abuser OR stereotype\n",
        "# NIDA: https://www.drugabuse.gov/nidamed-medical-health-professionals/health-professions-education/words-matter-terms-to-use-avoid-when-talking-about-addiction\n",
        "# Words Matter: Words to avoid when talking about addiction:\n",
        "# Included: Addict, User, Abuser, Junkie, Alcoholic, Drunk, Habit, Dirty,\n",
        "# Added in this study: stigma, bias, stereotype, shame, blame (From studies on stigma, bias, and types of stigmatization referenced in literature)\n",
        "# Not included: clean, addicted baby, opioid substitution replacement therapy, medication-assisted treatment, former addict, reformed adict\n",
        "\n",
        "# Negative Patient Descriptors: Documenting Racial Bias in the Electronic Health Record, Sun et al. 2022\n",
        "# \"non-adherent\", \"aggressive\", \"agitated\", \"angry\", \"challenging\", \"combative\", \"non-compliant\", \"confront\", \"non-cooperative\", \"defensive\", \"exaggerate\", \"hysterical\", \"un-pleasant\", \"refuse\", \"resist\"\n",
        "bias_stem_words = [\"addict\",\"user\",\"abuser\",\"junkie\",\"alcoholic\", \"drunk\", \"habit\", \"dirty\", \"stigma\",\"bias\",\"stereotype\",\"shame\",\"blame\",\"drug-seeking\",\"nonadherent\", \"aggressive\", \"agitated\", \"angry\", \"challenging\", \"combative\", \"noncompliant\", \"confront\", \"noncooperative\", \"defensive\", \"exaggerate\", \"hysterical\", \"unpleasant\", \"refuse\", \"resist\"]\n",
        "\n",
        "\n",
        "\n",
        "bias_words_df = pd.DataFrame({\n",
        "    'stem_word': bias_stem_words\n",
        "})"
      ],
      "metadata": {
        "id": "0ZoYHIJf8Q0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "bias_words_df['most_similar_words'] = bias_words_df['stem_word'].apply(model.most_similar)\n",
        "\n",
        "bias_words_df_2 = bias_words_df.explode(\"most_similar_words\", ignore_index=True)\n",
        "bias_words_df_2['new_word_id'] = range(1, 1 + len(bias_words_df_2))\n",
        "# bias_words_df_2[['similar_word','similarity_score']] =\n",
        "words_sep = pd.DataFrame(bias_words_df_2['most_similar_words'].values.tolist())\n",
        "words_sep['new_word_id'] = range(1, 1 + len(bias_words_df_2))\n",
        "bias_words_3 = bias_words_df_2.merge(words_sep, on = 'new_word_id')\n",
        "#bias_words_3['similar_word'], bias_words_3['score'] = bias_words_3[3],bias_words_3[4]\n",
        "\n",
        "bias_words_3= bias_words_3.rename(columns={0: \"similar_word\", 1: \"score\"})\n",
        "bias_words_3[\"Relevant_to_study\"] = \"\"\n",
        "bias_words_3.to_csv(\"stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\")\n",
        "\n",
        "bias_words_3"
      ],
      "metadata": {
        "id": "6QKm74hL-TG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f915277f-6f45-43d1-97f8-f0df3910e5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    stem_word                most_similar_words  new_word_id similar_word  \\\n",
              "0      addict    (exaddict, 0.8582410216331482)            1     exaddict   \n",
              "1      addict     (addict*, 0.8445701003074646)            2      addict*   \n",
              "2      addict    (deaddict, 0.8363768458366394)            3     deaddict   \n",
              "3      addict  (methaddict, 0.8306370973587036)            4   methaddict   \n",
              "4      addict     (addicts, 0.8289745450019836)            5      addicts   \n",
              "..        ...                               ...          ...          ...   \n",
              "285    resist    (wresists, 0.7534369230270386)          286     wresists   \n",
              "286    resist   (withstand, 0.7353253364562988)          287    withstand   \n",
              "287    resist    (resist's, 0.7309495210647583)          288     resist's   \n",
              "288    resist  (resisting/, 0.7280867695808411)          289   resisting/   \n",
              "289    resist    (resistry, 0.7255228161811829)          290     resistry   \n",
              "\n",
              "        score Relevant_to_study  \n",
              "0    0.858241                    \n",
              "1    0.844570                    \n",
              "2    0.836377                    \n",
              "3    0.830637                    \n",
              "4    0.828975                    \n",
              "..        ...               ...  \n",
              "285  0.753437                    \n",
              "286  0.735325                    \n",
              "287  0.730950                    \n",
              "288  0.728087                    \n",
              "289  0.725523                    \n",
              "\n",
              "[290 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d41b428a-d6f9-48f3-8be2-d2b334275782\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stem_word</th>\n",
              "      <th>most_similar_words</th>\n",
              "      <th>new_word_id</th>\n",
              "      <th>similar_word</th>\n",
              "      <th>score</th>\n",
              "      <th>Relevant_to_study</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>addict</td>\n",
              "      <td>(exaddict, 0.8582410216331482)</td>\n",
              "      <td>1</td>\n",
              "      <td>exaddict</td>\n",
              "      <td>0.858241</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>addict</td>\n",
              "      <td>(addict*, 0.8445701003074646)</td>\n",
              "      <td>2</td>\n",
              "      <td>addict*</td>\n",
              "      <td>0.844570</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>addict</td>\n",
              "      <td>(deaddict, 0.8363768458366394)</td>\n",
              "      <td>3</td>\n",
              "      <td>deaddict</td>\n",
              "      <td>0.836377</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>addict</td>\n",
              "      <td>(methaddict, 0.8306370973587036)</td>\n",
              "      <td>4</td>\n",
              "      <td>methaddict</td>\n",
              "      <td>0.830637</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>addict</td>\n",
              "      <td>(addicts, 0.8289745450019836)</td>\n",
              "      <td>5</td>\n",
              "      <td>addicts</td>\n",
              "      <td>0.828975</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>resist</td>\n",
              "      <td>(wresists, 0.7534369230270386)</td>\n",
              "      <td>286</td>\n",
              "      <td>wresists</td>\n",
              "      <td>0.753437</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>resist</td>\n",
              "      <td>(withstand, 0.7353253364562988)</td>\n",
              "      <td>287</td>\n",
              "      <td>withstand</td>\n",
              "      <td>0.735325</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>resist</td>\n",
              "      <td>(resist's, 0.7309495210647583)</td>\n",
              "      <td>288</td>\n",
              "      <td>resist's</td>\n",
              "      <td>0.730950</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>resist</td>\n",
              "      <td>(resisting/, 0.7280867695808411)</td>\n",
              "      <td>289</td>\n",
              "      <td>resisting/</td>\n",
              "      <td>0.728087</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>resist</td>\n",
              "      <td>(resistry, 0.7255228161811829)</td>\n",
              "      <td>290</td>\n",
              "      <td>resistry</td>\n",
              "      <td>0.725523</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>290 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d41b428a-d6f9-48f3-8be2-d2b334275782')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d41b428a-d6f9-48f3-8be2-d2b334275782 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d41b428a-d6f9-48f3-8be2-d2b334275782');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following 10 most similar words identified, we'll use  stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv to filter out words deemed irrelevant to study by JL and DW."
      ],
      "metadata": {
        "id": "sIrhzlVq-Y1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misspelling Generator\n",
        "*"
      ],
      "metadata": {
        "id": "4RATkUDy-Nx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Misspelling Generator\n",
        "\n",
        "\n",
        "\n",
        "def generate_spelling_variants(seedwordlist, word_vectors, semantic_search_length=500, levenshtein_threshold = 0.85, setting = 1):\n",
        "    \"\"\"\n",
        "        setting -> 0 = weighted levenshtein ratios\n",
        "                -> 1 = standard levenshtein ratios\n",
        "\n",
        "    :param seedwordlist:            list of words for which spelling variants are to be generated\n",
        "    :param word_vectors:            the word vector model\n",
        "    :param semantic_search_length:  the number of semantically similar terms to include in each iteration\n",
        "    :param levenshtein_threshold:   the threshold for levenshtein ratio\n",
        "\n",
        "    :return: dictionary containing the seedwords as key and all the variants as a list of values\n",
        "\n",
        "    \"\"\"\n",
        "    vars = defaultdict(list)\n",
        "    for seedword in seedwordlist:\n",
        "        #a dictionary to hold all the variants, key: the seedword, value: the list of possible misspellings\n",
        "        #a dynamic list of terms that are still to be expanded\n",
        "        terms_to_expand = []\n",
        "        terms_to_expand.append(seedword)\n",
        "        all_expanded_terms = []\n",
        "        level = 1\n",
        "        while len(terms_to_expand)>0:\n",
        "                t = terms_to_expand.pop(0)\n",
        "                all_expanded_terms.append(t)\n",
        "                try:\n",
        "                    similars = word_vectors.most_similar(t, topn=semantic_search_length)\n",
        "                    for similar in similars:\n",
        "                        similar_term = similar[0]\n",
        "                        if setting == 1:\n",
        "                            seq_score = Levenshtein.ratio(str(similar_term),seedword)\n",
        "                        if setting == 0:\n",
        "                            seq_score = weighted_levenshtein_ratio(str(similar_term), seedword)\n",
        "                        if seq_score>levenshtein_threshold:\n",
        "                            if not re.search(r'\\_',similar_term):\n",
        "                                vars[seedword].append(similar_term)\n",
        "                                if not similar_term in all_expanded_terms and not similar_term in terms_to_expand:\n",
        "                                    terms_to_expand.append(similar_term)\n",
        "                except:\n",
        "                        pass\n",
        "                level+=1\n",
        "        vars[seedword] = list(set(vars[seedword]))\n",
        "    return vars\n",
        "\n",
        "# Read in CSV of manually pruned list of first round expansion of Doubt lexicon\n",
        "bias_stem_words_round_2_raw = pd.read_csv(\"stigmatizing_word_list_round_1_dw_pruned.csv\")\n",
        "# filter for 0s\n",
        "bias_stem_words_round_2 = bias_stem_words_round_2_raw[bias_stem_words_round_2_raw[\"Relevant_to_study\"]==1]\n",
        "\n",
        "bias_stem_words_round_2.to_csv(\"stigma_word_list_round_2.csv\")\n",
        "\n",
        "bias_stem_words_round_2[\"similar_word\"] = bias_stem_words_round_2[\"similar_word\"].replace(\"_\", \" \", regex = True)\n",
        "\n",
        "bias_expanded_word_list = bias_stem_words_round_2[\"similar_word\"]\n",
        "\n",
        "expanded = generate_spelling_variants(bias_expanded_word_list, model, semantic_search_length=500, levenshtein_threshold = 0.85, setting = 1)\n",
        "\n",
        "df = pd.DataFrame.from_dict(expanded, orient ='index')\n",
        "\n",
        "df.to_csv(\"stigma_expanded_misspellings.csv\")"
      ],
      "metadata": {
        "id": "fediWTrj-Mro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github Code"
      ],
      "metadata": {
        "id": "uicKnEZFeAid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git config --global user.email \"andrew.walker@emory.edu\"\n",
        "#!git config --global user.name \"drew-walkerr\"\n",
        "#!git add \"stigmatizing_labels_lexicon_dev.ipynb\" \"stigmatizing_labels_descriptors_lexicon_stem_and_similar_round1.csv\"\n"
      ],
      "metadata": {
        "id": "BUnt32YSeC2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!git commit -m \"created working BioWordVec expanded words for stigmatizing labels lexicon\"\n",
        "#!git push origin master # https://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@github.com/drew-walkerr/Diss_Detecting_Provider_Bias.git"
      ],
      "metadata": {
        "id": "R6ooORlVeIwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}